Hey everyone, and welcome to our final session in this module. We’ve covered a lot of ground—from privacy to safety, sustainability, and legality. Last time, we focused on keeping AI systems on the right side of the law. Today, we’re turning to something just as crucial: respecting user autonomy and ensuring people are truly protected in AI-driven mobility.

Let’s kick things off by talking a bit about autonomy. If you think about it, autonomy is really about giving users the steering wheel—not just literally, but figuratively too. Imagine you’re using an e-scooter app. You expect to see a map, choose your own route, decide when to start and stop, and get clear info about pricing. If the app quietly nudges you toward longer, pricier trips just because it predicts you’ll pay more, that’s manipulation, not choice. Designers must create systems that empower, not covertly steer, users.

Now, how do we make sure users actually have that control? One way to protect autonomy is transparency. If AI suggests a specific route or service, users should know it’s AI-driven and get a plain-language explanation—maybe there’s traffic ahead or a safety concern. When people understand why a recommendation appears, they can make informed decisions.

Still, choice alone isn’t enough. Systems must also guard against unfair treatment. Imagine two passengers being charged very different fares for the same trip because an algorithm assumes one can pay more. That’s not only unethical—it’s illegal under consumer protection laws. Fairness has to be built in from the start, with testing to spot and prevent bias.

Another pillar of protection is data privacy. Mobility apps often know your travel patterns, locations, and possibly your companions. This is sensitive information, and users deserve clarity on what’s collected, how it’s stored, and what rights they have—such as correcting errors or requesting deletion. Strong privacy safeguards aren’t optional; laws like the GDPR make them mandatory, and they’re vital for public trust.

We also need to ensure access to rights and remedies. AI should simplify—not obscure—how people find and use their entitlements, whether that’s getting a refund, contesting a charge, or canceling a booking. The best platforms make this information easy to find and act on.

So, to bring it all together: respecting autonomy and protecting users aren’t just lofty goals. They’re concrete requirements grounded in law and essential for earning public trust. If we get this right, we don’t just create smarter mobility services—we build systems people actually want to use. Thanks for joining me throughout this module.
