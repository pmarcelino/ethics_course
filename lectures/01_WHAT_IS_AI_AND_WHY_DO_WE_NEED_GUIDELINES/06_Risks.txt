Hey again, and thanks for sticking with me as we wrap up this module. We’ve already explored AI’s benefits and challenges—how it boosts efficiency and personalization, but also raises issues like trust and transparency. Now, let’s focus on something we can’t ignore: the risks AI brings to mobility and transport.

First up: cybersecurity. This is where things can get serious very quickly. Imagine a city’s smart traffic lights, all synced to ease rush hour. Now, picture someone hacking that system. The result? Not just traffic jams, but potential accidents or chaos across the city. As vehicles, trains, and buses become more connected, they also become tempting targets for cyberattacks. Whether it’s ransomware freezing a subway line or hackers disrupting ride-share apps, these threats don’t just cause minor glitches—they threaten safety and shake public trust.

But it’s not just technical risks. There’s a social side we must consider. AI depends on huge amounts of data to make decisions. If that data is biased or incomplete—perhaps overlooking certain neighborhoods or ignoring the needs of people with disabilities—the AI’s choices can end up unfair. It’s like using a map missing entire sections of the city: if you’re off the map, you won’t get where you need to go. Without careful attention, AI systems risk deepening existing inequalities, leaving some people stranded while others move ahead.

Next, consider reliability and safety. Picture an autonomous bus facing a sudden thunderstorm or unexpected roadworks. If its programming hasn’t prepared it for those surprises, it could struggle to respond safely. One high-profile accident can severely damage public trust and delay wider acceptance of these technologies. People need confidence that AI will work not just in ideal conditions, but also in real-world challenges.

Then there’s data privacy. Transport systems collect vast information about where we go, when, and sometimes personal details too. If too few companies or agencies control this data, power becomes concentrated, and privacy risks grow. Breaches and unauthorized tracking are real concerns. People deserve to know their movements aren’t monitored without consent.

Finally, transparency and human oversight matter deeply. AI can seem like a black box—even developers may struggle to explain some decisions. If you’re denied a ride or charged unexpectedly and can’t get a clear reason, trust erodes. Relying solely on automation without human intervention can be dangerous, especially in emergencies where quick judgment is crucial.

So, to sum up: AI in mobility and transport is packed with promise, but it brings a whole set of risks—cyber, social, safety, privacy, and transparency. Tackling these head-on with careful planning, inclusive design, and ongoing oversight is the only way we make sure the benefits reach everyone. Thanks for your attention and curiosity throughout this module. It’s been great exploring these ideas with you.
