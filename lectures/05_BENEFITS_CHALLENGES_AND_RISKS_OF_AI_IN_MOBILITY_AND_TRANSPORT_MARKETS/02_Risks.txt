Hello again, and thanks for sticking with me as we wrap up this module. Now, if you recall, we’ve already gone over the upsides and the stumbling blocks of AI—how it can boost efficiency, adapt to our needs, and also where things can get tricky with trust or transparency. So, for our final topic together, let’s zero in on something that really can’t be swept under the rug: the risks that come along for the ride when we invite AI into mobility and transport.

Let’s kick things off with cybersecurity, because honestly, that’s where things can get real, real fast. Picture this: a city’s smart traffic lights all working in sync, smoothing out the morning rush hour. But what happens if someone manages to hack into that system? Suddenly, you’re not just dealing with gridlock, but potentially with accidents or even citywide chaos. The more we connect our vehicles, trains, and buses, the juicier the target for people who want to do harm. Whether it’s a ransomware attack freezing a subway line or hackers messing with ride-share apps, these aren’t just minor glitches—they can shake public trust and put safety at risk.

But let’s not stop at the technical side. There’s a social dimension here, too, and it’s one we can’t ignore. AI uses massive amounts of data to make decisions, but if that data is already skewed—maybe it overlooks certain neighborhoods, or doesn’t reflect the needs of people with disabilities—the decisions AI makes can end up being unfair. It’s a bit like using a map that’s missing whole sections of the city: you’ll never get where you need to go if you’re not on the map in the first place. If we’re not careful, these systems can deepen existing divides, leaving some folks stranded while others zip ahead.

Reliability and safety are another piece of the puzzle. Imagine an autonomous bus facing a sudden thunderstorm or unexpected construction. If its training didn’t include those curveballs, it might struggle to handle them safely. And let’s face it, one high-profile accident can set back public acceptance by years. People need to feel confident that AI won’t just work under perfect conditions, but also when things get tough.

And then there’s the matter of data—lots and lots of data. Transport systems are collecting information about where we go, when, and sometimes even more personal details. If only a few companies or agencies control all that info, there’s a risk of power being concentrated in the wrong hands. Plus, privacy breaches aren’t just theoretical; they’re happening. Whether it’s unauthorized tracking or data leaks, people deserve to know their journeys aren’t being watched without their say-so.

One last thing before we wrap up: transparency and human oversight. AI can feel like a black box—sometimes even the folks who build these systems can’t fully explain why a particular decision happened. If you get denied a ride or charged a strange fee, and there’s no clear reason, that’s frustrating and erodes trust. And in emergencies, relying solely on automation without a way for humans to step in can be downright dangerous.

So, to sum up: AI in mobility and transport is packed with promise, but it brings a whole set of risks—cyber, social, safety, privacy, and transparency. Tackling these head-on with careful planning, inclusive design, and ongoing oversight is the only way we make sure the benefits reach everyone. Thanks for your attention and curiosity throughout this module. It’s been great exploring these ideas with you.