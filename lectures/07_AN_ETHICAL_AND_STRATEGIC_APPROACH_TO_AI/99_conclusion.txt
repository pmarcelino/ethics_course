Alright, so let’s take a step back and see what we’ve covered in this module. We started off by exploring how strategy and alignment really set the tone for ethical AI in urban mobility. Then we dove into the nitty-gritty—things like risk identification, data quality, and what it actually means to build systems that are equitable and respect human autonomy. We also tackled privacy, responsibility, and the all-important role of human supervision. And of course, we talked transparency, legal compliance, and why ongoing training and error documentation are non-negotiables. It’s a lot, but all of these pieces fit together to create a truly ethical and strategic approach to AI.

Now, looking ahead, things get even more interesting. Next up, we’ll zoom in on the legal and regulatory side of things. We’ll break down what compliance really means in this space, why regulation is evolving, and what “high risk” actually looks like in mobility and transport. So if you’ve ever wondered how AI rules get made—and enforced—this next module is for you. Let’s keep going!