Hi everyone, glad to have you back. Last time, we unpacked the role of AMT in steering the ethical and practical side of AI for mobility, which set the stage for what we’re diving into today. So, let’s take a step back and get the bigger picture: how does Europe actually regulate Artificial Intelligence? More specifically, what’s this “risk-based approach” everyone keeps talking about, and why does it matter for anyone working in mobility or transport?

Picture this: you’re building an AI system, maybe one that helps plan city bus routes in Porto or optimizes ride-sharing in Paris. Now, wouldn’t it be confusing if every country had totally different rules about what’s allowed? The EU’s answer is a single, unified set of AI regulations. Whether you’re in Lisbon, Berlin, or Warsaw, the same standards apply. This harmonization isn’t just bureaucratic talk—it means less red tape, fewer surprises, and a much clearer path for anyone creating or using AI across Europe. It’s like switching from a patchwork of local road signs to one universal traffic signal system.

But here’s where it gets interesting: not all AI is treated the same. Think of it like airport security. Some passengers—say, a diplomat—might breeze through fast-track, while others get a closer look. The EU’s risk-based approach works the same way. Instead of regulating every AI system equally, it asks: “How likely is this AI to cause harm? And if something does go wrong, just how bad could it get?” It’s all about matching the level of scrutiny to the potential consequences.

Now, what’s clever is how the rules don’t hinge on how fancy or popular the tech is, but on what the AI actually does. So, an AI chatbot answering bus schedule questions isn’t lumped in with an autonomous vehicle navigating busy city streets. The law looks at context: the specific application, not just the tech powering it. That way, the rules stay relevant, even as AI keeps evolving.

Let’s break down the four risk levels you’ll hear about. At the top, you’ve got “unacceptable risk” AI—these are systems that are flat-out banned, like those designed to manipulate people’s behavior in sneaky ways or exploit vulnerable groups. Next rung down, we hit “high-risk” AI. Think about tools that influence who gets a job, who gets a loan, or, in our world, who gets green lights at intersections. These require strict checks and documentation. Then there’s “limited-risk” AI, which mainly needs to be upfront with users—like telling you you’re chatting with a bot. Finally, “minimal-risk” systems, which are so everyday and harmless, they’re not regulated at all.

So, what does this spell out for you, whether you’re designing, selling, or using AI in mobility? Basically, everything depends on the risk category your system lands in. High-risk? Be ready for paperwork and audits. Anything sketchy or banned? That’s serious trouble. For a sector where safety and rights are front and center, knowing these categories isn’t optional—it’s crucial.

To wrap it up, the EU’s risk-based model aims to keep people safe without putting the brakes on innovation. Next up, we’ll zero in on what makes mobility and transport such a hot spot for high-risk AI. Catch you then.