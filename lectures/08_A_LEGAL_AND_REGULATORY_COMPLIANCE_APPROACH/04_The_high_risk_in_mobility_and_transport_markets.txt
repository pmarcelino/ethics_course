Alright, everyone, let’s jump right in. Last time, we tackled how the EU’s risk-based approach tries to keep AI in check. Today, let’s zoom in on where those rules really hit the pavement—or the tracks or even the skies. Our focus is the high-risk world of mobility and transport markets. And let me tell you, this is where AI gets real, fast. 

So, why are these AI systems in transport considered such a big deal? Imagine the kind of tech that’s running metro trains, orchestrating city-wide traffic signals, or steering massive cargo ships through tight waterways. We’re not talking about your car’s music recommendation system here. These are the brains behind the scenes, moving millions safely from A to B. If something goes wrong—a train’s AI misjudges a signal, or a self-driving bus makes a poor decision—the consequences are immediate and serious. It’s a bit like being the referee in a high-stakes game: one bad call, and everything can turn upside down.

Now, let’s get practical. How do the rules actually sort out what’s high-risk? The EU doesn’t leave much to chance here. Any AI that acts as a product or a key safety part in transport—whether it’s controlling your local tram or managing an entire rail network—gets labeled high-risk straight away. It’s not just because these systems are technically advanced; it’s because they’re woven into the fabric of daily life. Think of it as giving these technologies a bright yellow vest so everyone knows they need extra attention.

But what does this special status actually mean for the teams designing or rolling out these systems? Well, before anything gets the official green light, there’s something called a conformity assessment. Picture this as a super-thorough pre-flight checklist, but for AI. The system has to prove it’s not just clever, but also safe, reliable, and fair—long before it ever interacts with the public. This involves checking for cybersecurity, accuracy, transparency, and making sure all the paperwork is in order. If the system can’t clear these hurdles, it doesn’t leave the hangar, so to speak.

Let’s walk through what’s expected from companies. First off, risk management is non-negotiable: they need to hunt down and fix any risks throughout the AI’s entire life. Data quality is another big one—feeding in messy or biased data is like giving bad directions to a driver, and that never ends well. Providers also have to log everything the system does, so if problems pop up, there’s a trail to follow. Transparency is front and center; users should always know what the AI can—and can’t—do. Human oversight is built in, so if things start to go sideways, people can step in and take the wheel. And of course, these systems need to be tough enough to fend off cyber threats and run accurately.

Public agencies, by the way, have a special job. If they want to unleash high-risk AI in public transport, they’re required to check for impacts on fundamental rights—think privacy, fairness, and non-discrimination—before anything goes live.

So, as we wrap up this module, remember: AI in mobility and transport is full of promise but comes with real responsibilities. The rules are there not to slow us down, but to keep us moving safely and fairly. Thanks for sticking with me through this journey.